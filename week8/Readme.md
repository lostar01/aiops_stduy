1. 尝试修改实战三，并接入 Ollama 实现自托管大模型（Qwen2）推理
```
  llmEndpoint: "http://192.168.1.111:11434/v1"
  llmToken: "ollama"
  llmModel: "qwen2.5"
```

修改实战四，配置 RagFlow 接入 Ollama 实现自托管大模型推理
<img src=./img/ragflow.png/>